{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Knowledge_distillation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hectic97/Boostcamp-AI-Tech/blob/main/U-stage/Week8/Knowledge_distillation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChzaoF9qJ6mO"
      },
      "source": [
        "# 경량화 과제\n",
        "경량화 세번째 과제 파일 입니다.\n",
        "\n",
        "이번 과제는 지식증류방법(Knowledge distillation)을 활용하여 Student 모델 학습하고, alpha와 temperature에 따라 정확도가 어떻게 변화하는지 확인해보도록하겠습니다. \n",
        "\n",
        "\n",
        "세부 내용은 다음과 같습니다. \n",
        "\n",
        "```\n",
        "과제3. 지식증류방법(Knowledge distillation)을 활용하여 Student 모델 학습\n",
        "1. Teacher 모델정의\n",
        "2. alpha 와 Temperature 변화시켜 정확도 측정 해보기  \n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGqfEGA1sLH3"
      },
      "source": [
        "# GPU 할당확인 \n",
        "import torch\n",
        "\n",
        "print('CUDA GPU availalbe : {}'.format(torch.cuda.is_available()))\n",
        "try:\n",
        "    print('{} GPU(s) is(are) allocated'.format(torch.cuda.device_count()))\n",
        "except:\n",
        "    print('GPUs are not allocated. Current runtime is on CPU.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rPVpwGciG9G"
      },
      "source": [
        "## 드라이브 연결 및 PATH 설정 \n",
        "\n",
        "드라이브 마운트와 PATH설정을 하는 단계입니다. 예제는 아래와 같은 상황에서 돌아가도록 맞춰졌으며, \n",
        "자신의 드라이브 환경에 맞추어 설정하시면 되겠습니다. \n",
        "\n",
        "```\n",
        "dataset\n",
        "  |\n",
        "  |-  teacher.pth\n",
        "  |-  경량화 과제_3(문제)\n",
        "  |-  APY170401435_subset_13gb\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB4vHB2DKc3R"
      },
      "source": [
        "# 코랩 내 드라이브와 연결\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs4blXeksMvk"
      },
      "source": [
        "# Path 설정 \n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/gdrive/My Drive/dataset/'):\n",
        "  os.mkdir('/content/gdrive/My Drive/dataset/')\n",
        "os.chdir('/content/gdrive/My Drive/dataset/') # Data_Path\n",
        "current_path = os.getcwd() # current folder\n",
        "print('current_path', current_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lamerfwXI2ml"
      },
      "source": [
        "## 파일이동 확인 \n",
        "정상적으로 파일이 옮겨졌는지 확인 합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT-tgg99sM5S"
      },
      "source": [
        "from glob import glob\n",
        "\n",
        "image = sorted(glob('./total/*.jpg'))\n",
        "meta = sorted(glob('./total/*.metadata'))\n",
        "\n",
        "if len(image) == len(meta):\n",
        "    print('train data ({} files) unzip succeed'.format(len(image)))\n",
        "else:\n",
        "    print('train data unzip failed')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaEkAnq9M1rJ"
      },
      "source": [
        "## 사용자 정의함수 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aluNej1wsM7m"
      },
      "source": [
        "# import \n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import json\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import imutils\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from collections import deque, defaultdict\n",
        "import re \n",
        "import matplotlib.image as mpimg\n",
        "from collections import OrderedDict\n",
        "from skimage import io, transform\n",
        "from math import *\n",
        "import xml.etree.ElementTree as ET \n",
        "\n",
        "\n",
        "# torch \n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61sZ9MH2SMGm"
      },
      "source": [
        "# Dataset / Dataloader\n",
        "\n",
        "\n",
        "1. Image_Dataset_ : dataset 데이터셋을 정의하는 객체\n",
        "2. get_loader : Dataloader 객체를 return하는 함수\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE0r9YYWsM99"
      },
      "source": [
        "class AttributeDict(dict):\n",
        "    def __init__(self):\n",
        "        self.__dict__ = self\n",
        "        \n",
        "\n",
        "class ConfigTree:\n",
        "    def __init__(self):\n",
        "        self.DATASET = AttributeDict()\n",
        "        self.SYSTEM = AttributeDict()\n",
        "        self.TRAIN = AttributeDict()\n",
        "        self.MODEL = AttributeDict()\n",
        "        self.KD = AttributeDict()\n",
        "\n",
        "class Image_Dataset_(Dataset):\n",
        "    def __init__(self, root, cfg=None, transform=None):\n",
        "        \"\"\"\n",
        "        root : './data/'\n",
        "        \"\"\"\n",
        "        super(Image_Dataset_, self).__init__()\n",
        "        self.root = root\n",
        "        self.cfg = cfg\n",
        "        self.transform = transform\n",
        "        self.images = sorted(glob(self.root + '/*.jpg'))\n",
        "        self.annotations = sorted(glob(self.root + '/*.metadata'))\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "# ---------------------------------------------------------------------------- #\n",
        "#  1. getitem 완성시키기\n",
        "# * 주의 * 밑에 사용된 get_gt, label2logit 함수를 이용하여 label 을 만들어야함.\n",
        "#   1) .metadata를 get_gt로 읽기\n",
        "#   2) label2logt을 활용하여 1) 값 int 로 변경 \n",
        "# ---------------------------------------------------------------------------- #\n",
        "\n",
        "       # 채우기 #\n",
        "\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, label\n",
        "        \n",
        "    def __len__(self):\n",
        "        assert len(self.images) == len(self.annotations), \"# of image files and # of meatadata files do not match\"\n",
        "        return len(self.images)\n",
        "    \n",
        "     \n",
        "# ---------------------------------------------------------------------------- #\n",
        "#  과제 1 에서 작성한 함수를 적용\n",
        "# .metadata 를 읽어서 22번째 값(male or female) 을 가져오기 ... \n",
        "# ---------------------------------------------------------------------------- #\n",
        "\n",
        "    def get_gt(self, meta_file):\n",
        "        gt_class = None\n",
        "        meta_file = Path(meta_file)\n",
        "        f = open(meta_file, \"r\")\n",
        "        \n",
        "\n",
        "        # 채우기 #\n",
        "\n",
        "\n",
        "        return gt_class\n",
        "    \n",
        "    def label2logit(self,label):\n",
        "        str_dict = {\n",
        "            'female': 0,\n",
        "            'male':1\n",
        "        }\n",
        "        return str_dict[label]\n",
        "\n",
        "def get_loader(dataset, cfg, shuffle=True):\n",
        "    return DataLoader(dataset, batch_size=cfg.TRAIN.BATCH_SIZE, shuffle=shuffle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJu0pqBpSZQ8"
      },
      "source": [
        "# Image Augmentation \n",
        " get_augmentation : image transform 객체를 return하는 함수\n",
        "- resize_crop \n",
        "- random_flip\n",
        "- color_jitter\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhRuQP7_SYi9"
      },
      "source": [
        "def get_augmentation(size=224, use_flip=True, use_color_jitter=False, use_gray_scale=False, use_normalize=False):\n",
        "    resize_crop = transforms.RandomResizedCrop(size=size)\n",
        "    random_flip = transforms.RandomHorizontalFlip(p=0.5)\n",
        "    color_jitter = transforms.RandomApply([\n",
        "        transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)\n",
        "    ], p=0.8)\n",
        "    \n",
        "    gray_scale = transforms.RandomGrayscale(p=0.2)\n",
        "    normalize = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "    to_tensor = transforms.ToTensor()\n",
        "    \n",
        "    transforms_array = np.array([resize_crop, random_flip, color_jitter, gray_scale, to_tensor, normalize])\n",
        "    transforms_mask = np.array([True, use_flip, use_color_jitter, use_gray_scale, True, use_normalize])\n",
        "    \n",
        "    transform = transforms.Compose(transforms_array[transforms_mask])\n",
        "    \n",
        "    return transform\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_21uHH6_c0B"
      },
      "source": [
        "## Student model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnQwsAd0_a29"
      },
      "source": [
        "# ---------------------------------------------------------------------------- #\n",
        "# (코드 채우기) 과제 2에서 정의한 Student model \n",
        "# ---------------------------------------------------------------------------- #\n",
        "\n",
        "class Student(nn.Module):\n",
        "  def __init__(self):\n",
        "      super().__init__()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKtz5a1zSsB6"
      },
      "source": [
        "## Train\n",
        "\n",
        "- Trainer : config에서 주어진 실험 조건들로 학습을 행하는 객체"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z62oQNucSrfJ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from datetime import timedelta\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, optimizer, cfg, device, train_loader, teacher=None, val_loader=None):\n",
        "        self.cfg = cfg\n",
        "        self.device = device\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.save_path = cfg.BASE_SAVE_DIR\n",
        "        \n",
        "        if teacher:\n",
        "            self.teacher = teacher.to(device)\n",
        "            self.temperature = cfg.KD.TEMPERATURE\n",
        "            self.alpha = cfg.KD.ALPHA\n",
        "        \n",
        "        print(\"[INFO] using gpu {}\".format(cfg.SYSTEM.GPU))\n",
        "\n",
        "        self.model = model.to(device)\n",
        "        \n",
        "        update_params = [p for p in model.parameters() if p.requires_grad]\n",
        "        self.optimizer = optimizer(update_params, lr=cfg.TRAIN.BASE_LR, weight_decay=cfg.TRAIN.WEIGHT_DECAY)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.total_step = 0\n",
        "        self.training_time = 0\n",
        "        \n",
        "        print(model)\n",
        "        print()\n",
        "        print(optimizer)\n",
        "        print()\n",
        "        \n",
        "            \n",
        "    def KD_train_eval(self, name='KD_student'):\n",
        "        print(\"training KD start!\\n\")\n",
        "        for epoch in range(self.cfg.TRAIN.EPOCH):\n",
        "            self.KD_train_one_epoch(epoch)\n",
        "            self.test_one_epoch(epoch)\n",
        "            self.save_model(epoch,name)\n",
        "    \n",
        "    def KD_train_one_epoch(self,epoch):\n",
        "        print('\\nEpoch: %d' % epoch)\n",
        "        print(f'[INFO] Temperature {self.temperature}, Alpha {self.alpha}')\n",
        "        self.model.train()\n",
        "        self.teacher.eval()\n",
        "        \n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for batch_idx, (inputs, targets) in enumerate(self.train_loader):\n",
        "            inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "            \n",
        "            outputs = self.model(inputs) # student\n",
        "            teacher_outputs = self.teacher(inputs) # teacher \n",
        "            loss = self.loss_fn_kd(outputs, targets, teacher_outputs)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            if batch_idx % self.cfg.TRAIN.PERIOD ==0:\n",
        "                print('Loss: %.3f | Acc: %.3f%% ' %(train_loss/(batch_idx+1),100.*correct/total))\n",
        "      \n",
        "        \n",
        "    def test_one_epoch(self,epoch):\n",
        "        self.model.eval()\n",
        "        \n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (inputs, targets) in enumerate(self.val_loader):\n",
        "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, targets)\n",
        "\n",
        "                test_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += targets.size(0)\n",
        "                correct += predicted.eq(targets).sum().item()\n",
        "                \n",
        "        print(f'Accuracy of the network on the {total} test images: %d %%' % (\n",
        "        100 * correct / total))\n",
        "        \n",
        "    # ---------------------------------------------------------------------------- #\n",
        "    # (코드 채우기) Kd Loss 정의하기 \n",
        "    # ---------------------------------------------------------------------------- #  \n",
        "        \n",
        "    def loss_fn_kd(self, outputs, labels, teacher_outputs):\n",
        "        \"\"\"\n",
        "        params = T & alpha in `self`\n",
        "        Compute the knowledge-distillation (KD) loss given outputs, labels.\n",
        "        \"Hyperparameters\": temperature and alpha\n",
        "        NOTE: the KL Divergence for PyTorch comparing the softmaxs of teacher\n",
        "        and student expects the input tensor to be log probabilities\n",
        "        \"\"\"\n",
        "        \n",
        "        # 채우기 \n",
        "\n",
        "\n",
        "\n",
        "        return KD_loss\n",
        "        \n",
        "    def save_model(self, epoch, name='KD'):\n",
        "        print('saved model {}'.format(self.save_path)) \n",
        "        if not os.path.exists(self.save_path):\n",
        "            os.mkdir(self.save_path)\n",
        "        file_name = '{}_{}.pth'.format(name, epoch)\n",
        "        file_path = os.path.join(self.save_path, file_name)\n",
        "        torch.save(self.model.state_dict(), file_path)\n",
        "            \n",
        "        return None \n",
        "              "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZMk3fs_cXNN"
      },
      "source": [
        "## Teacher Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Sj0z_xNcWf5"
      },
      "source": [
        "class Teacher(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.pretrain_extractor = self.freeze()\n",
        "\n",
        "           \n",
        "    def freeze(self):\n",
        "        model = models.resnet50(pretrained=True)\n",
        "        num_classes = 2\n",
        "        in_features = model.fc.in_features\n",
        "        model.fc = nn.Sequential(nn.Linear(in_features, 512),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(0.2),\n",
        "                                 nn.Linear(512,num_classes))\n",
        "        \n",
        "        return model \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.pretrain_extractor(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJAzbWaUTD_7"
      },
      "source": [
        "# Config\n",
        "\n",
        "모델 변수(즉, 모델의 학습 조건을 설정해주는 공간 ) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEU_UTcdSCr0"
      },
      "source": [
        "# config\n",
        "config = ConfigTree()\n",
        "config.SYSTEM.GPU = 0 # GPU 번호 \n",
        "config.BASE_SAVE_DIR = './outputs' # 모델 파라미터가 저장되는 위치\n",
        "\n",
        "config.DATASET.ROOT = \"./total\" # 데이터 위치\n",
        "config.DATASET.NUM_CLASSES = 2 # 분류해야 하는 클래스 종류의 수 \n",
        "config.DATASET.RATIO = 0.3 # train, test split 비율 \n",
        "config.DATASET.TEACHER_WEIGHT_PATH = './teacher_9.pth' # teacher weight 경로\n",
        "\n",
        "\n",
        "\n",
        "# hyperparameter ... \n",
        "# 사용할 augmentation\n",
        "config.TRAIN.AUGMENTATION = {'size' : 224,\n",
        "                             'use_flip' : True,\n",
        "                             'use_color_jitter' : False,\n",
        "                             'use_normalize' : True\n",
        "} \n",
        "config.TRAIN.WEIGHT_DECAY = 0.9\n",
        "config.TRAIN.EPOCH = 30 # 총 학습 에폭 \n",
        "config.TRAIN.BATCH_SIZE = 32 # 배치 사이즈 \n",
        "config.TRAIN.BASE_LR = 1e-04 # 러닝 레이트 \n",
        "config.TRAIN.PERIOD = 1 # loss 측정 주기\n",
        "config.MODEL.OPTIM = 'SGD' # 'ASGD, Adam, rmsprop etc...'\n",
        "\n",
        "config.TRAIN.TEACHER_MODEL = Teacher()\n",
        "config.TRAIN.STUDENT_MODEL = Student()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkOJZzwBS9iY"
      },
      "source": [
        "## main \n",
        "\n",
        "학습 코드를 실행 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne5psROhR11H"
      },
      "source": [
        "def main(config):\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  data_root = config.DATASET.ROOT\n",
        "  transform = get_augmentation(**config.TRAIN.AUGMENTATION)\n",
        "  dataset = Image_Dataset_(data_root, config, transform=transform)\n",
        "\n",
        "  len_valid_set = int(config.DATASET.RATIO*len(dataset))\n",
        "  len_train_set = len(dataset) - len_valid_set\n",
        "\n",
        "  print(\"The length of Train set is {}\".format(len_train_set))\n",
        "  print(\"The length of Valid set is {}\".format(len_valid_set))\n",
        "\n",
        "  train_dataset , valid_dataset,  = torch.utils.data.random_split(dataset , [len_train_set, len_valid_set])\n",
        "\n",
        "  # shuffle and batch the datasets\n",
        "  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config.TRAIN.BATCH_SIZE, shuffle=True,)\n",
        "  valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=config.TRAIN.BATCH_SIZE, shuffle=True,)\n",
        "\n",
        "\n",
        "  # Load Teacher dict \n",
        "  teacher = config.TRAIN.TEACHER_MODEL\n",
        "  weight_path = config.DATASET.TEACHER_WEIGHT_PATH \n",
        "\n",
        "  teacher.load_state_dict(torch.load(weight_path,map_location='cuda:0'))\n",
        "  for param in teacher.parameters():\n",
        "      param.requires_grad = False\n",
        "      \n",
        "  teacher.to(device)\n",
        "\n",
        "\n",
        "  student = config.TRAIN.STUDENT_MODEL\n",
        "  student.to(device)\n",
        "  optimizer = optim.__dict__[config.MODEL.OPTIM]\n",
        "\n",
        "\n",
        "  if config.KD.ON_OFF == 'on':\n",
        "    trainer = Trainer(student, optimizer, config, device, train_loader, teacher=teacher, val_loader=valid_loader)\n",
        "    trainer.KD_train_eval()\n",
        "  else:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz1BMaoBKDQw"
      },
      "source": [
        "## Student Network Knowledge Distillation 해보기 \n",
        "\n",
        "총 9 가지 조합을 사용 하여 해보기\n",
        "- Temperature = {1, 20, 50}\n",
        "- Alpha = {0.2, 0.5, 0.8}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zIPr3fKKIAG"
      },
      "source": [
        "# Temperature: 1 &  Alpha: 0.2\n",
        "config.KD.ON_OFF = 'on' # student를 knowledge distillation으로 학습한다면 'on'\n",
        "config.KD.TEMPERATURE = 1\n",
        "config.KD.ALPHA = 0.2\n",
        "main(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ROzo6CpzwK6"
      },
      "source": [
        "# Temperature: 1 &  Alpha: 0.5\n",
        "config.KD.ON_OFF = 'on' # student를 knowledge distillation으로 학습한다면 'on'\n",
        "config.KD.TEMPERATURE = 1\n",
        "config.KD.ALPHA = 0.5\n",
        "main(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DnJwb9gzwPA"
      },
      "source": [
        "# Temperature: 1 &  Alpha: 0.8\n",
        "config.KD.ON_OFF = 'on' # student를 knowledge distillation으로 학습한다면 'on'\n",
        "config.KD.TEMPERATURE = 1\n",
        "config.KD.ALPHA = 0.8\n",
        "main(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEdPJkbLfqmq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}